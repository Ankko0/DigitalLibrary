{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "http://www.labirint.ru/books/673048/\n",
      "http://www.labirint.ru/books/720904/\n",
      "{'Author': 'Бакман Фредрик', 'Category': 'Современная проза', 'Title': 'Медвежий угол', 'Year': 2019, 'Code': '673048', 'Pages': 528}\n",
      "Author Бакман Фредрик\n",
      "Category Современная проза\n",
      "Title Медвежий угол\n",
      "Year 2019\n",
      "Code 673048\n",
      "Pages 528\n",
      "http://www.labirint.ru/books/629135/\n",
      "http://www.labirint.ru/books/721460/\n",
      "{'Author': 'Полярный Александр', 'Category': 'Современная проза', 'Title': 'Мятная сказка', 'Year': 2019, 'Code': '629135', 'Pages': 160}\n",
      "Author Полярный Александр\n",
      "Category Современная проза\n",
      "Title Мятная сказка\n",
      "Year 2019\n",
      "Code 629135\n",
      "Pages 160\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "\n",
    "\n",
    "book_id = 710146 #740146\n",
    "url = 'http://www.labirint.ru' # url для второй страницы\n",
    "r = requests.get(url)\n",
    "print (r.status_code)\n",
    "with open('pages/test.html', 'wb') as output_file:\n",
    "  output_file.write(r.text.encode('utf8'))\n",
    "\n",
    "# def ParseURLS (text):\n",
    "#     links =[]\n",
    "#     url = 'https://www.labirint.ru/genres/2497/?order=popularity&way=forward/' # url для второй страницы\n",
    "#     page = requests.get(url)\n",
    "#     soup = BeautifulSoup(page.text)\n",
    "    \n",
    "\n",
    "def Parse (text):\n",
    "    \n",
    "    #try:\n",
    "        result ={}\n",
    "        soup = BeautifulSoup(r.text)\n",
    "        Author = soup.find('div', {'class': 'authors'}).find('a').text\n",
    "        Category = soup.find_all('span', {'itemprop': 'title'})[1].text\n",
    "        name = soup.find('div', {'id': 'product-title'}, {'class': 'prodtitle'}).h1.text.split(':')[1].strip()\n",
    "        publisher = soup.find('div',{'class': 'publisher'}).text\n",
    "        year = int(publisher.split(', ')[1][:4])\n",
    "        code = soup.find('div',{'class': 'articul'}).text\n",
    "        code = re.search(r'\\d+', code)\n",
    "        code = code.group(0)\n",
    "        pages = soup.find('div',{'class': 'pages2'}).text\n",
    "        pages = pages.split(': ')[1]\n",
    "        #print(pages)\n",
    "        pages = re.match(r'\\d{1,4}', pages)\n",
    "        pages = int(pages.group(0))\n",
    "        result= {'Author': Author, 'Category': Category, 'Title': name, 'Year': year, 'Code': code, 'Pages': pages}\n",
    "        return result\n",
    "    #except AttributeError: \n",
    "        #return 0\n",
    "    \n",
    "# Book = Parse(r.text)\n",
    "# if r.status_code == 200 and Book != 0:\n",
    "#     for key, value in Book.items():\n",
    "#         print(key, value)\n",
    "# else:\n",
    "#     print('Error ' + str(book_id) + '\\n')\n",
    "\n",
    "\n",
    "# links =[]\n",
    "def ParseLinkList(genre_id):\n",
    "    #genre_id = 1852\n",
    "    listUrls = []\n",
    "    url = 'https://www.labirint.ru/genres/%g/?order=popularity&way=forward/' %(genre_id)# url для второй страницы\n",
    "    page = requests.get(url)\n",
    "    if page.status_code==200:\n",
    "#     with open('pages/testList.html', 'wb') as output_file:\n",
    "#       output_file.write(page.text.encode('utf8'))\n",
    "        soup = BeautifulSoup(page.text)\n",
    "        # print(soup)\n",
    "        #%debug\n",
    "        Book_list = soup.find_all('div', {'class': 'product need-watch' }) #class: product need-watch product_ebooks  Для электр. книг\n",
    "        Book_list\n",
    "        for item in Book_list:\n",
    "            listUrls.append(item.find('a', {'class': \"cover\"}).get('href'))\n",
    "        return listUrls\n",
    "\n",
    "Urls = ParseLinkList(1852)\n",
    "# print(url + Urls.pop())\n",
    "# r = requests.get(url + Urls.pop())\n",
    "# Book = Parse(r.text)\n",
    "# print(Book)\n",
    "count =0\n",
    "while  Urls and count <=1:\n",
    "    ASD =url + Urls.pop()\n",
    "    r = requests.get(ASD)\n",
    "    print(ASD)\n",
    "    #print (r.text)\n",
    "    Book = Parse(r.text)\n",
    "    print(url + Urls.pop())\n",
    "    print(Book)\n",
    "    if r.status_code == 200 and Book != 0:\n",
    "        for key, value in Book.items():\n",
    "            print(key, value)\n",
    "    else:\n",
    "        print('Error ' + str(book_id) + '\\n')\n",
    "    count+=1\n",
    "    \n",
    "# def Print(dictionary):\n",
    "    \n",
    "\n",
    "# f = open('text.txt', 'w')\n",
    "# f.write('URL: ' + url + str(book_id) + '\\n')\n",
    "# f.write('Author: ' + film_list + '\\n')\n",
    "# f.write('Category: ' + tetile + '\\n')\n",
    "# f.write('Year: ' + str(year) + '\\n')\n",
    "# f.write('Code: ' + code + '\\n')\n",
    "# f.write('Pages: ' + str(pages) + '\\n')\n",
    "# f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
